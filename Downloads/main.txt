# For running inference on the TF-Hub module.
import tensorflow as tf
import tensorflow_hub as hub

# For camera access
import cv2

# For drawing onto the image.
import numpy as np
from PIL import ImageDraw, ImageColor, ImageFont, Image

# For local model
import tarfile
import os.path
import pyttsx3


def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()):
    draw = ImageDraw.Draw(image)
    image_width, image_height = image.size
    (left, right, top, bottom) = (xmin * image_width, xmax * image_width,
                                  ymin * image_height, ymax * image_height)
    draw.line([(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],
              width=thickness, fill=color)

    # If the total height of the display strings added to the top of the bounding
    # box exceeds the top of the image, stack the strings below the bounding box
    # instead of above.
    display_str_height = [font.getsize(ds)[1] for ds in display_str_list]
    # Each display_str has a top and bottom margin of 0.05x
    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_height)

    if top > total_display_str_height:
        text_bottom = top
    else:
        text_bottom = top + display_str_height
    # Reverse list and print from bottom to top.
    for display_str in display_str_list[::-1]:
        text_width, text_height = font.getsize(display_str)
        margin = np.ceil(0.05 * text_height)
        draw.rectangle([(left, text_bottom - text_height - 2 * margin),
                        (left + text_width, text_bottom)],
                       fill=color)
        draw.text((left + margin, text_bottom - text_height - margin),
                  display_str,
                  fill="black",
                  font=font)
        text_bottom -= text_height - 2 * margin


def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):
    colors = list(ImageColor.colormap.values())
    font = ImageFont.load_default()

    for i in range(min(boxes.shape[0], max_boxes)):
        if scores[i] >= min_score:
            ymin, xmin, ymax, xmax = tuple(boxes[i])
            display_str = "{}: {}%".format(class_names[i].decode("ascii"),
                                           int(100 * scores[i]))
            color = colors[hash(class_names[i]) % len(colors)]
            image_pil = Image.fromarray(np.uint8(image)).convert("RGB")
            draw_bounding_box_on_image(
                image_pil,
                ymin,
                xmin,
                ymax,
                xmax,
                color,
                font,
                display_str_list=[display_str])
            np.copyto(image, np.array(image_pil))
            # engine = pyttsx3.init()
            # engine.say(class_names[i].decode("ascii"))
            # engine.runAndWait()
        return image


def run_detection(tf_detector):
    video_stream = cv2.VideoCapture(0)

    while True:
        ret, frame = video_stream.read()
        converted_image = tf.image.convert_image_dtype(frame, tf.float32)[tf.newaxis, ...]
        result = tf_detector(converted_image)
        result = {key: value.numpy() for key, value in result.items()}

        print("Found %d objects." % len(result["detection_scores"]))

        image_with_boxes = draw_boxes(
            frame, result["detection_boxes"],
            result["detection_class_entities"], result["detection_scores"])

        cv2.imshow('object detection', image_with_boxes)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # After the loop release the cap object
    video_stream.release()
    # Destroy all the windows
    cv2.destroyAllWindows()


# module_handle = "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1"
module_handle = "https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1"
detector = hub.load(module_handle).signatures['default']
run_detection(detector)
